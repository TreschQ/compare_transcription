import streamlit as st
import os
import glob
import difflib
import re
import json
from pathlib import Path
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go

st.set_page_config(
    page_title="Comparateur de Transcriptions",
    page_icon="üìù",
    layout="wide"
)

def get_available_scopes(base_directory):
    """R√©cup√®re la liste des p√©rim√®tres disponibles"""
    transcripts_dir = os.path.join(base_directory, 'transcripts')
    improved_dir = os.path.join(base_directory, 'improved_transcripts')
    
    scopes = set()
    
    # Chercher les dossiers dans transcripts et improved_transcripts
    if os.path.exists(transcripts_dir):
        scopes.update([d for d in os.listdir(transcripts_dir) if os.path.isdir(os.path.join(transcripts_dir, d))])
    
    if os.path.exists(improved_dir):
        scopes.update([d for d in os.listdir(improved_dir) if os.path.isdir(os.path.join(improved_dir, d))])
    
    return sorted(list(scopes))

def load_transcript_files(base_directory, selected_scope=None):
    """Charge tous les fichiers de transcription depuis les dossiers par p√©rim√®tre"""
    transcripts_dir = os.path.join(base_directory, 'transcripts')
    improved_dir = os.path.join(base_directory, 'improved_transcripts')
    
    files_data = {}
    
    if selected_scope == "TOUS":
        # Charger tous les p√©rim√®tres
        scopes = get_available_scopes(base_directory)
        scopes = [s for s in scopes if s != "TOUS"]
    elif selected_scope:
        # Charger un p√©rim√®tre sp√©cifique
        scopes = [selected_scope]
    else:
        # Mode r√©trocompatible (recherche dans le dossier racine)
        videos_dir = os.path.join(base_directory, 'videos')
        
        transcript_files = glob.glob(os.path.join(videos_dir, 'transcript_formatted_*.txt'))
        improved_files = glob.glob(os.path.join(improved_dir, 'improved_*.txt'))
        
        # Charger les fichiers originaux
        for file_path in transcript_files:
            filename = os.path.basename(file_path)
            base_name = filename.replace('transcript_formatted_', '').replace('.txt', '')
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            files_data[base_name] = {
                'original': content,
                'original_path': file_path,
                'improved': None,
                'improved_path': None,
                'scope': 'LEGACY'
            }
        
        # Charger les fichiers am√©lior√©s
        for file_path in improved_files:
            filename = os.path.basename(file_path)
            base_name = filename.replace('improved_', '').replace('.txt', '')
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            if base_name in files_data:
                files_data[base_name]['improved'] = content
                files_data[base_name]['improved_path'] = file_path
        
        return files_data
    
    # Charger les fichiers par p√©rim√®tre
    for scope in scopes:
        scope_transcripts_dir = os.path.join(transcripts_dir, scope)
        scope_improved_dir = os.path.join(improved_dir, scope)
        
        if os.path.exists(scope_transcripts_dir):
            transcript_files = glob.glob(os.path.join(scope_transcripts_dir, 'transcript_formatted_*.txt'))
        else:
            transcript_files = []
            
        if os.path.exists(scope_improved_dir):
            improved_files = glob.glob(os.path.join(scope_improved_dir, 'improved_*.txt'))
        else:
            improved_files = []
        
        # Charger les fichiers originaux du p√©rim√®tre
        for file_path in transcript_files:
            filename = os.path.basename(file_path)
            base_name = filename.replace('transcript_formatted_', '').replace('.txt', '')
            file_key = f"{scope}:{base_name}" if selected_scope == "TOUS" else base_name
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            files_data[file_key] = {
                'original': content,
                'original_path': file_path,
                'improved': None,
                'improved_path': None,
                'scope': scope
            }
        
        # Charger les fichiers am√©lior√©s du p√©rim√®tre
        for file_path in improved_files:
            filename = os.path.basename(file_path)
            base_name = filename.replace('improved_', '').replace('.txt', '')
            file_key = f"{scope}:{base_name}" if selected_scope == "TOUS" else base_name
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            if file_key in files_data:
                files_data[file_key]['improved'] = content
                files_data[file_key]['improved_path'] = file_path
    
    return files_data

def find_common_start(text1, text2, min_words=4):
    """Trouve le point de d√©part commun entre deux textes (minimum 4-5 mots)"""
    words1 = text1.split()
    words2 = text2.split()
    
    # Chercher une s√©quence de mots communs
    for i in range(len(words1) - min_words + 1):
        for j in range(len(words2) - min_words + 1):
            # V√©rifier si on a au moins min_words mots identiques cons√©cutifs
            match_count = 0
            for k in range(min(len(words1) - i, len(words2) - j)):
                if words1[i + k].lower() == words2[j + k].lower():
                    match_count += 1
                else:
                    break
            
            if match_count >= min_words:
                # Retourner les indices de d√©but dans les textes originaux
                start1 = len(' '.join(words1[:i]))
                start2 = len(' '.join(words2[:j]))
                if start1 > 0:
                    start1 += 1  # Ajouter l'espace
                if start2 > 0:
                    start2 += 1  # Ajouter l'espace
                return start1, start2
    
    return 0, 0

def tokenize_text(text):
    """Tokenise le texte en mots et ponctuation"""
    # S√©parer les mots et la ponctuation
    tokens = re.findall(r'\w+|[^\w\s]', text)
    return tokens

def align_and_compare_texts(original, improved, min_common_words=4):
    """Aligne deux textes et g√©n√®re une comparaison avec surbrillance"""
    
    # Trouver le point de d√©part commun
    start1, start2 = find_common_start(original, improved, min_common_words)
    
    # Extraire les parties align√©es
    aligned_original = original[start1:]
    aligned_improved = improved[start2:]
    
    # Tokeniser
    tokens_original = tokenize_text(aligned_original)
    tokens_improved = tokenize_text(aligned_improved)
    
    # Utiliser difflib pour comparer
    matcher = difflib.SequenceMatcher(None, tokens_original, tokens_improved)
    
    original_html = []
    improved_html = []
    
    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        if tag == 'equal':
            # Tokens identiques
            for i in range(i1, i2):
                original_html.append(f'<span style="color: #cccccc;">{tokens_original[i]}</span>')
            for j in range(j1, j2):
                improved_html.append(f'<span style="color: #cccccc;">{tokens_improved[j]}</span>')
        
        elif tag == 'replace':
            # Tokens modifi√©s
            for i in range(i1, i2):
                original_html.append(f'<span style="background-color: #8B0000; color: #ffffff; padding: 2px 4px; border-radius: 3px; font-weight: bold;">{tokens_original[i]}</span>')
            for j in range(j1, j2):
                improved_html.append(f'<span style="background-color: #1E3A8A; color: #ffffff; padding: 2px 4px; border-radius: 3px; font-weight: bold;">{tokens_improved[j]}</span>')
        
        elif tag == 'delete':
            # Tokens supprim√©s
            for i in range(i1, i2):
                original_html.append(f'<span style="background-color: #8B0000; color: #ffffff; text-decoration: line-through; padding: 2px 4px; border-radius: 3px;">{tokens_original[i]}</span>')
        
        elif tag == 'insert':
            # Tokens ajout√©s
            for j in range(j1, j2):
                improved_html.append(f'<span style="background-color: #166534; color: #ffffff; padding: 2px 4px; border-radius: 3px; font-weight: bold;">{tokens_improved[j]}</span>')
    
    # Rejoindre les tokens avec des espaces appropri√©s
    original_result = rebuild_text_with_spacing(original_html)
    improved_result = rebuild_text_with_spacing(improved_html)
    
    return original_result, improved_result, start1, start2

def rebuild_text_with_spacing(token_list):
    """Reconstruit le texte avec un espacement appropri√©"""
    if not token_list:
        return ""
    
    result = []
    for i, token in enumerate(token_list):
        # Extraire le contenu du token (enlever les balises HTML pour l'analyse)
        content = re.sub(r'<[^>]+>', '', token)
        
        if i == 0:
            result.append(token)
        else:
            # Ajouter un espace avant sauf pour la ponctuation
            if content not in '.,!?;:)]}' and not content.startswith("'"):
                result.append(' ')
            result.append(token)
    
    return ''.join(result)

def calculate_diff_stats(original, improved):
    """Calcule les statistiques de diff√©rences"""
    tokens_original = tokenize_text(original)
    tokens_improved = tokenize_text(improved)
    
    matcher = difflib.SequenceMatcher(None, tokens_original, tokens_improved)
    
    equal_count = 0
    replace_count = 0
    delete_count = 0
    insert_count = 0
    
    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        if tag == 'equal':
            equal_count += i2 - i1
        elif tag == 'replace':
            replace_count += max(i2 - i1, j2 - j1)
        elif tag == 'delete':
            delete_count += i2 - i1
        elif tag == 'insert':
            insert_count += j2 - j1
    
    total_tokens = len(tokens_original)
    changed_tokens = replace_count + delete_count + insert_count
    
    return {
        'total_original': len(tokens_original),
        'total_improved': len(tokens_improved),
        'equal': equal_count,
        'replaced': replace_count,
        'deleted': delete_count,
        'inserted': insert_count,
        'change_percentage': (changed_tokens / total_tokens * 100) if total_tokens > 0 else 0
    }

def filter_transcription_segments(original_text, improved_text):
    """
    Filtre la transcription am√©lior√©e selon des r√®gles strictes :
    - D√©but : Commencer seulement si 90% des 30 premiers tokens correspondent
    - Fin : Arr√™ter d√®s qu'on trouve 30 tokens cons√©cutifs non correspondants
    
    Args:
        original_text (str): Texte original
        improved_text (str): Texte am√©lior√© 
    
    Returns:
        str: Texte am√©lior√© filtr√©
    """
    if not original_text or not improved_text:
        return improved_text
    
    # Tokeniser comme dans l'app
    tokens_original = tokenize_text(original_text)
    tokens_improved = tokenize_text(improved_text)
    
    if len(tokens_original) < 30 or len(tokens_improved) < 30:
        return improved_text
    
    # 1. Trouver le point de d√©part (90% de correspondance sur 30 tokens)
    start_pos = None
    original_start_30 = tokens_original[:30]
    
    for i in range(len(tokens_improved) - 29):
        improved_segment_30 = tokens_improved[i:i+30]
        
        # Calculer la correspondance exacte
        matches = sum(1 for orig, imp in zip(original_start_30, improved_segment_30) if orig.lower() == imp.lower())
        similarity = matches / 30
        
        if similarity >= 0.9:  # 90% de correspondance
            start_pos = i
            break
    
    if start_pos is None:
        return improved_text
    
    # 2. Utiliser difflib comme dans l'app pour d√©tecter les changements
    matcher = difflib.SequenceMatcher(None, tokens_original, tokens_improved[start_pos:])
    
    end_pos = len(tokens_improved)
    consecutive_non_equal = 0
    current_pos = start_pos
    
    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        if tag == 'equal':
            consecutive_non_equal = 0
            current_pos = start_pos + j2
        else:
            # Compter les tokens non correspondants
            non_equal_count = max(i2 - i1, j2 - j1)
            consecutive_non_equal += non_equal_count
            
            if consecutive_non_equal >= 30:
                end_pos = start_pos + j1  # Position o√π ont commenc√© les non-correspondances
                break
            
            current_pos = start_pos + j2
    
    # 3. Extraire le texte filtr√© en pr√©servant le formatage
    if start_pos > 0 or end_pos < len(tokens_improved):
        # Reconstruire le texte avec le bon espacement
        filtered_tokens = tokens_improved[start_pos:end_pos]
        return rebuild_text_with_spacing(filtered_tokens)
    
    return improved_text

def calculate_all_diff_percentages(files_data):
    """Calcule les pourcentages d'√©cart pour toutes les transcriptions (avec filtrage automatique)"""
    percentages = []
    file_names = []
    scopes = []
    all_stats = []
    
    for file_name, data in files_data.items():
        if data['improved'] is not None:
            # Appliquer le filtrage automatiquement
            filtered_improved = filter_transcription_segments(data['original'], data['improved'])
            
            # Aligner les textes
            start1, start2 = find_common_start(data['original'], filtered_improved, 4)
            aligned_original = data['original'][start1:]
            aligned_improved = filtered_improved[start2:]
            
            # Calculer les stats
            stats = calculate_diff_stats(aligned_original, aligned_improved)
            percentages.append(stats['change_percentage'])
            file_names.append(file_name)
            scopes.append(data.get('scope', 'Unknown'))
            all_stats.append(stats)
    
    return percentages, file_names, scopes, all_stats

def calculate_global_token_stats(all_stats, scopes=None):
    """Calcule les statistiques globales de tokens"""
    if not all_stats:
        return None
    
    # Statistiques globales
    global_stats = {
        'total_files': len(all_stats),
        'total_tokens_original': sum(stat['total_original'] for stat in all_stats),
        'total_tokens_improved': sum(stat['total_improved'] for stat in all_stats),
        'total_equal': sum(stat['equal'] for stat in all_stats),
        'total_replaced': sum(stat['replaced'] for stat in all_stats),
        'total_deleted': sum(stat['deleted'] for stat in all_stats),
        'total_inserted': sum(stat['inserted'] for stat in all_stats)
    }
    
    # Calculer les pourcentages globaux
    total_changes = global_stats['total_replaced'] + global_stats['total_deleted'] + global_stats['total_inserted']
    global_stats['global_change_percentage'] = (total_changes / global_stats['total_tokens_original'] * 100) if global_stats['total_tokens_original'] > 0 else 0
    
    # Statistiques par p√©rim√®tre si disponible
    scope_stats = {}
    if scopes and len(set(scopes)) > 1:
        unique_scopes = list(set(scopes))
        for scope in unique_scopes:
            scope_indices = [i for i, s in enumerate(scopes) if s == scope]
            scope_data = [all_stats[i] for i in scope_indices]
            
            scope_stats[scope] = {
                'files': len(scope_data),
                'total_original': sum(stat['total_original'] for stat in scope_data),
                'total_improved': sum(stat['total_improved'] for stat in scope_data),
                'equal': sum(stat['equal'] for stat in scope_data),
                'replaced': sum(stat['replaced'] for stat in scope_data),
                'deleted': sum(stat['deleted'] for stat in scope_data),
                'inserted': sum(stat['inserted'] for stat in scope_data)
            }
            
            total_scope_changes = scope_stats[scope]['replaced'] + scope_stats[scope]['deleted'] + scope_stats[scope]['inserted']
            scope_stats[scope]['change_percentage'] = (total_scope_changes / scope_stats[scope]['total_original'] * 100) if scope_stats[scope]['total_original'] > 0 else 0
    
    return global_stats, scope_stats

def create_token_statistics_charts(all_stats, scopes=None):
    """Cr√©e des graphiques pour les statistiques de tokens"""
    if not all_stats:
        return None, None, None
    
    # Pr√©parer les donn√©es pour les graphiques
    data_for_charts = []
    for i, stat in enumerate(all_stats):
        scope = scopes[i] if scopes else 'All'
        data_for_charts.append({
            'Fichier': f"File {i+1}",
            'P√©rim√®tre': scope,
            'Supprim√©s': stat['deleted'],
            'Modifi√©s': stat['replaced'],
            'Ajout√©s': stat['inserted'],
            'Identiques': stat['equal']
        })
    
    df_tokens = pd.DataFrame(data_for_charts)
    
    # Graphique en barres empil√©es pour les types de changements
    fig_stacked = go.Figure()
    
    colors = {
        'Supprim√©s': '#8B0000',
        'Modifi√©s': '#1E3A8A', 
        'Ajout√©s': '#166534',
        'Identiques': '#cccccc'
    }
    
    for change_type in ['Supprim√©s', 'Modifi√©s', 'Ajout√©s', 'Identiques']:
        fig_stacked.add_trace(go.Bar(
            name=change_type,
            x=df_tokens['Fichier'],
            y=df_tokens[change_type],
            marker_color=colors[change_type]
        ))
    
    fig_stacked.update_layout(
        title="Distribution des types de changements de tokens par fichier",
        xaxis_title="Fichiers",
        yaxis_title="Nombre de tokens",
        barmode='stack',
        showlegend=True
    )
    
    # Graphique en secteurs pour la r√©partition globale
    global_stats, _ = calculate_global_token_stats(all_stats, scopes)
    
    fig_pie = go.Figure(data=[go.Pie(
        labels=['Identiques', 'Modifi√©s', 'Supprim√©s', 'Ajout√©s'],
        values=[global_stats['total_equal'], global_stats['total_replaced'], 
                global_stats['total_deleted'], global_stats['total_inserted']],
        hole=.3,
        marker_colors=[colors['Identiques'], colors['Modifi√©s'], colors['Supprim√©s'], colors['Ajout√©s']]
    )])
    
    fig_pie.update_layout(
        title="R√©partition globale des types de changements",
        annotations=[dict(text='Tokens', x=0.5, y=0.5, font_size=20, showarrow=False)]
    )
    
    # Graphique de distribution des changements par p√©rim√®tre (si applicable)
    fig_scope = None
    if scopes and len(set(scopes)) > 1:
        scope_totals = df_tokens.groupby('P√©rim√®tre')[['Supprim√©s', 'Modifi√©s', 'Ajout√©s']].sum()
        
        fig_scope = go.Figure()
        for change_type in ['Supprim√©s', 'Modifi√©s', 'Ajout√©s']:
            fig_scope.add_trace(go.Bar(
                name=change_type,
                x=scope_totals.index,
                y=scope_totals[change_type],
                marker_color=colors[change_type]
            ))
        
        fig_scope.update_layout(
            title="Total des changements par p√©rim√®tre",
            xaxis_title="P√©rim√®tres",
            yaxis_title="Nombre de tokens",
            barmode='group'
        )
    
    return fig_stacked, fig_pie, fig_scope

def create_distribution_chart(percentages, file_names, scopes=None):
    """Cr√©e un graphique de distribution des √©carts de tokens"""
    df_data = {
        'Fichier': file_names,
        '√âcart_pourcentage': percentages
    }
    
    if scopes:
        df_data['P√©rim√®tre'] = scopes
    
    df = pd.DataFrame(df_data)
    
    # Histogramme
    if scopes and len(set(scopes)) > 1:
        fig_hist = px.histogram(
            df, 
            x='√âcart_pourcentage',
            color='P√©rim√®tre',
            nbins=20,
            title="Distribution des √©carts de tokens (%) par p√©rim√®tre",
            labels={'√âcart_pourcentage': '√âcart de tokens (%)', 'count': 'Nombre de fichiers'}
        )
    else:
        fig_hist = px.histogram(
            df, 
            x='√âcart_pourcentage',
            nbins=20,
            title="Distribution des √©carts de tokens (%)",
            labels={'√âcart_pourcentage': '√âcart de tokens (%)', 'count': 'Nombre de fichiers'},
            color_discrete_sequence=['#1f77b4']
        )
    
    fig_hist.update_layout(
        xaxis_title="√âcart de tokens (%)",
        yaxis_title="Nombre de fichiers"
    )
    
    # Box plot
    if scopes and len(set(scopes)) > 1:
        fig_box = px.box(
            df,
            x='P√©rim√®tre',
            y='√âcart_pourcentage',
            title="R√©partition des √©carts de tokens par p√©rim√®tre",
            labels={'√âcart_pourcentage': '√âcart de tokens (%)', 'P√©rim√®tre': 'P√©rim√®tre'}
        )
        fig_box.update_layout(
            xaxis_title="P√©rim√®tre",
            yaxis_title="√âcart de tokens (%)"
        )
    else:
        fig_box = px.box(
            df,
            y='√âcart_pourcentage',
            title="R√©partition des √©carts de tokens",
            labels={'√âcart_pourcentage': '√âcart de tokens (%)'}
        )
        fig_box.update_layout(
            yaxis_title="√âcart de tokens (%)",
            showlegend=False
        )
    
    # Graphique en barres d√©taill√©
    if scopes and len(set(scopes)) > 1:
        fig_bar = px.bar(
            df.sort_values('√âcart_pourcentage', ascending=False),
            x='Fichier',
            y='√âcart_pourcentage',
            color='P√©rim√®tre',
            title="√âcarts de tokens par fichier et p√©rim√®tre",
            labels={'√âcart_pourcentage': '√âcart de tokens (%)', 'Fichier': 'Nom du fichier'}
        )
    else:
        fig_bar = px.bar(
            df.sort_values('√âcart_pourcentage', ascending=False),
            x='Fichier',
            y='√âcart_pourcentage',
            title="√âcarts de tokens par fichier",
            labels={'√âcart_pourcentage': '√âcart de tokens (%)', 'Fichier': 'Nom du fichier'},
            color='√âcart_pourcentage',
            color_continuous_scale='Viridis'
        )
    
    fig_bar.update_layout(
        xaxis_title="Fichiers",
        yaxis_title="√âcart de tokens (%)",
        xaxis={'tickangle': 45}
    )
    
    return fig_hist, fig_box, fig_bar, df

def load_nlp_analysis(base_directory, scope):
    """Charge les analyses NLP pour un p√©rim√®tre donn√©"""
    if scope == "TOUS" or not scope:
        return None
    
    analysis_file = os.path.join(base_directory, 'improved_transcripts', scope, f'nlp_analyses_{scope}.json')
    
    if not os.path.exists(analysis_file):
        return None
    
    try:
        with open(analysis_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        st.error(f"Erreur lors du chargement de l'analyse NLP : {e}")
        return None

def calculate_nlp_kpis(nlp_data):
    """Calcule les KPI moyens des types de changements √† partir des analyses NLP"""
    if not nlp_data or 'analyses' not in nlp_data:
        return None
    
    all_change_types = []
    
    for analysis in nlp_data['analyses']:
        if 'report_summary' in analysis and 'change_types' in analysis['report_summary']:
            change_types = analysis['report_summary']['change_types']
            all_change_types.append(change_types)
    
    if not all_change_types:
        return None
    
    # Calculer les moyennes pour chaque type de changement
    df = pd.DataFrame(all_change_types)
    means = df.mean()
    
    # Calculer le total moyen et les pourcentages
    total_mean = means.sum()
    percentages = (means / total_mean * 100) if total_mean > 0 else means * 0
    
    return {
        'means': means.to_dict(),
        'percentages': percentages.to_dict(),
        'total_files': len(all_change_types),
        'total_mean': total_mean
    }

def create_nlp_kpi_charts(kpi_data):
    """Cr√©e des graphiques pour les KPI des types de changements NLP"""
    if not kpi_data:
        return None, None
    
    means = kpi_data['means']
    percentages = kpi_data['percentages']
    
    # Couleurs pour chaque type de changement
    colors = {
        'orthographic': '#2E8B57',  # Vert fonc√©
        'grammatical': '#4169E1',   # Bleu royal
        'punctuation': '#FF6347',   # Rouge tomate
        'lexical': '#DAA520',       # Or
        'structural': '#8A2BE2',    # Violet
        'additions': '#32CD32',     # Vert lime
        'deletions': '#DC143C'      # Rouge cramoisi
    }
    
    # Graphique en barres des moyennes
    fig_means = go.Figure()
    
    change_types = list(means.keys())
    values = list(means.values())
    bar_colors = [colors.get(ct, '#666666') for ct in change_types]
    
    fig_means.add_trace(go.Bar(
        x=change_types,
        y=values,
        marker_color=bar_colors,
        text=[f'{v:.1f}' for v in values],
        textposition='auto'
    ))
    
    fig_means.update_layout(
        title="Moyenne des types de changements par fichier (Analyse NLP)",
        xaxis_title="Types de changements",
        yaxis_title="Nombre moyen de changements",
        showlegend=False
    )
    
    # Graphique en secteurs des pourcentages
    fig_pie = go.Figure(data=[go.Pie(
        labels=change_types,
        values=list(percentages.values()),
        hole=.3,
        marker_colors=[colors.get(ct, '#666666') for ct in change_types],
        textinfo='label+percent',
        textposition='auto'
    )])
    
    fig_pie.update_layout(
        title="R√©partition des types de changements (Analyse NLP)",
        annotations=[dict(text=f'Total: {kpi_data["total_mean"]:.1f}', x=0.5, y=0.5, font_size=16, showarrow=False)]
    )
    
    return fig_means, fig_pie

# Interface Streamlit
st.title("üìù Comparateur de Transcriptions")
st.markdown("Comparez les transcriptions originales avec les versions am√©lior√©es par l'IA")

# S√©lection du dossier et p√©rim√®tre
col1, col2, col3 = st.columns([2, 1, 1])

with col1:
    directory = st.text_input(
        "Dossier contenant les transcriptions:",
        value="output/",
        help="Dossier contenant les fichiers transcript_formatted_*.txt et improved_*.txt"
    )

with col2:
    # S√©lection du p√©rim√®tre
    if os.path.exists(directory):
        available_scopes = get_available_scopes(directory)
        if available_scopes:
            scope_options = ["TOUS"] + available_scopes
            selected_scope = st.selectbox(
                "P√©rim√®tre:",
                scope_options,
                help="S√©lectionnez un p√©rim√®tre sp√©cifique ou tous les p√©rim√®tres"
            )
        else:
            selected_scope = None
            st.warning("Aucun p√©rim√®tre d√©tect√©")
    else:
        selected_scope = None

with col3:
    min_common_words = st.slider(
        "Mots communs minimum:",
        min_value=3,
        max_value=8,
        value=4,
        help="Nombre minimum de mots cons√©cutifs identiques pour l'alignement"
    )

# Charger les fichiers si le dossier existe
if os.path.exists(directory):
    files_data = load_transcript_files(directory, selected_scope)
    
    if files_data:
        # Section Analyses des transcriptions
        
        available_files = [name for name, data in files_data.items() if data['improved'] is not None]
        
        if available_files:
            # Calculer les √©carts pour tous les fichiers
            with st.spinner("Calcul des √©carts pour tous les fichiers..."):
                percentages, file_names, scopes, all_stats = calculate_all_diff_percentages(files_data)
                
                if percentages:
                    # Afficher le p√©rim√®tre s√©lectionn√©
                    if selected_scope:
                        if selected_scope == "TOUS":
                            st.info(f"üìä Analyse de tous les p√©rim√®tres ({len(set(scopes))} p√©rim√®tres: {', '.join(sorted(set(scopes)))})")
                        else:
                            st.info(f"üìä Analyse du p√©rim√®tre: **{selected_scope}**")
                    
                    # === SECTION STATISTIQUES GLOBALES DE TOKENS ===
                    st.markdown("## üî¢ Statistiques globales des tokens")
                    
                    # Calculer les statistiques globales
                    global_stats, scope_stats = calculate_global_token_stats(all_stats, scopes)
                    
                    # Affichage des m√©triques principales
                    col1, col2, col3, col4, col5 = st.columns(5)
                    
                    with col1:
                        st.metric("üìÅ Fichiers analys√©s", global_stats['total_files'])
                    
                    with col2:
                        st.metric("üîó Tokens originaux", f"{global_stats['total_tokens_original']:,}")
                    
                    with col3:
                        st.metric("‚ú® Tokens am√©lior√©s", f"{global_stats['total_tokens_improved']:,}")
                    
                    with col4:
                        diff_tokens = global_stats['total_tokens_improved'] - global_stats['total_tokens_original']
                        st.metric("üìà Diff√©rence nette", f"{diff_tokens:+,}")
                    
                    with col5:
                        st.metric("üéØ % changement global", f"{global_stats['global_change_percentage']:.1f}%")
                    
                    # M√©triques d√©taill√©es des changements
                    st.markdown("### üìä D√©tail des changements de tokens")
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("üü¢ Identiques", f"{global_stats['total_equal']:,}")
                    
                    with col2:
                        st.metric("üî¥ Supprim√©s", f"{global_stats['total_deleted']:,}")
                    
                    with col3:
                        st.metric("üîµ Modifi√©s", f"{global_stats['total_replaced']:,}")
                    
                    with col4:
                        st.metric("üü° Ajout√©s", f"{global_stats['total_inserted']:,}")
                    
                    # Graphiques des statistiques de tokens
                    st.markdown("### üìà Visualisations des changements de tokens")
                    
                    fig_stacked, fig_pie, fig_scope = create_token_statistics_charts(all_stats, scopes)
                    
                    if fig_stacked and fig_pie:
                        tab_tokens1, tab_tokens2, tab_tokens3 = st.tabs(["ü•ß R√©partition globale", "üìä Par fichier", "üèõÔ∏è Par p√©rim√®tre"])
                        
                        with tab_tokens1:
                            st.plotly_chart(fig_pie, use_container_width=True)
                        
                        with tab_tokens2:
                            st.plotly_chart(fig_stacked, use_container_width=True)
                        
                        with tab_tokens3:
                            if fig_scope:
                                st.plotly_chart(fig_scope, use_container_width=True)
                            else:
                                st.info("Visualisation par p√©rim√®tre disponible uniquement avec l'option 'TOUS'")
                    
                    # Tableau des statistiques par p√©rim√®tre
                    if scope_stats and len(scope_stats) > 1:
                        st.markdown("### üèõÔ∏è Statistiques d√©taill√©es par p√©rim√®tre")
                        
                        scope_df_data = []
                        for scope, stats in scope_stats.items():
                            scope_df_data.append({
                                'P√©rim√®tre': scope,
                                'Fichiers': stats['files'],
                                'Tokens orig.': f"{stats['total_original']:,}",
                                'Tokens am√©l.': f"{stats['total_improved']:,}",
                                'Identiques': f"{stats['equal']:,}",
                                'Supprim√©s': f"{stats['deleted']:,}",
                                'Modifi√©s': f"{stats['replaced']:,}",
                                'Ajout√©s': f"{stats['inserted']:,}",
                                '% changement': f"{stats['change_percentage']:.1f}%"
                            })
                        
                        scope_df = pd.DataFrame(scope_df_data)
                        st.dataframe(scope_df, use_container_width=True)
                    
                    # === SECTION KPI ANALYSES NLP ===
                    # Charger et afficher les KPI NLP si disponibles pour le p√©rim√®tre s√©lectionn√©
                    if selected_scope and selected_scope != "TOUS":
                        nlp_data = load_nlp_analysis(directory, selected_scope)
                        if nlp_data:
                            st.markdown("## üß† KPI des Types de Changements (Analyse NLP)")
                            
                            kpi_data = calculate_nlp_kpis(nlp_data)
                            if kpi_data:
                                # Afficher les m√©triques principales
                                col1, col2, col3, col4 = st.columns(4)
                                
                                with col1:
                                    st.metric("üìÑ Fichiers analys√©s (NLP)", kpi_data['total_files'])
                                
                                with col2:
                                    st.metric("üìä Changements moyens/fichier", f"{kpi_data['total_mean']:.1f}")
                                
                                with col3:
                                    top_type = max(kpi_data['means'], key=kpi_data['means'].get)
                                    st.metric("üèÜ Type principal", top_type.title())
                                
                                with col4:
                                    top_percentage = kpi_data['percentages'][top_type]
                                    st.metric("üìà % du type principal", f"{top_percentage:.1f}%")
                                
                                # Tableaux d√©taill√©s des moyennes
                                st.markdown("### üìã D√©tail des moyennes par type de changement")
                                
                                kpi_df_data = []
                                for change_type, mean_value in kpi_data['means'].items():
                                    percentage = kpi_data['percentages'][change_type]
                                    kpi_df_data.append({
                                        'Type de changement': change_type.title(),
                                        'Moyenne': f"{mean_value:.2f}",
                                        'Pourcentage': f"{percentage:.1f}%"
                                    })
                                
                                kpi_df = pd.DataFrame(kpi_df_data)
                                kpi_df = kpi_df.sort_values('Moyenne', key=lambda x: x.str.replace(',', '.').astype(float), ascending=False)
                                st.dataframe(kpi_df, use_container_width=True)
                                
                                # Graphiques des KPI NLP
                                fig_means, fig_pie = create_nlp_kpi_charts(kpi_data)
                                
                                if fig_means and fig_pie:
                                    tab_nlp1, tab_nlp2 = st.tabs(["üìä Moyennes par type", "ü•ß R√©partition"])
                                    
                                    with tab_nlp1:
                                        st.plotly_chart(fig_means, use_container_width=True)
                                    
                                    with tab_nlp2:
                                        st.plotly_chart(fig_pie, use_container_width=True)
                                
                                st.markdown("---")
                            else:
                                st.warning("‚ö†Ô∏è Impossible de calculer les KPI √† partir des donn√©es NLP")
                        else:
                            st.info(f"‚ÑπÔ∏è Aucune analyse NLP disponible pour le p√©rim√®tre **{selected_scope}**")
                    
                    # === SECTION DISTRIBUTION DES √âCARTS ===
                    st.markdown("---")
                    st.markdown("## üìä Distribution des pourcentages d'√©carts")
                    
                    # Cr√©er les graphiques
                    fig_hist, fig_box, fig_bar, df = create_distribution_chart(percentages, file_names, scopes)
                    
                    # Afficher les statistiques globales
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("Nombre de fichiers", len(percentages))
                    
                    with col2:
                        st.metric("√âcart moyen", f"{pd.Series(percentages).mean():.1f}%")
                    
                    with col3:
                        st.metric("√âcart m√©dian", f"{pd.Series(percentages).median():.1f}%")
                    
                    with col4:
                        st.metric("√âcart max", f"{pd.Series(percentages).max():.1f}%")
                    
                    # Statistiques par p√©rim√®tre si TOUS est s√©lectionn√©
                    if selected_scope == "TOUS" and len(set(scopes)) > 1:
                        st.markdown("### üìà Statistiques par p√©rim√®tre")
                        scope_stats = df.groupby('P√©rim√®tre')['√âcart_pourcentage'].agg(['count', 'mean', 'median', 'max']).round(1)
                        scope_stats.columns = ['Nb fichiers', 'Moyenne (%)', 'M√©diane (%)', 'Max (%)']
                        st.dataframe(scope_stats, use_container_width=True)
                    
                    # Onglets pour diff√©rentes visualisations
                    tab1, tab2, tab3, tab4 = st.tabs(["üìà Histogramme", "üì¶ Box Plot", "üìä Par fichier", "üìã Tableau"])
                    
                    with tab1:
                        st.plotly_chart(fig_hist, use_container_width=True)
                    
                    with tab2:
                        st.plotly_chart(fig_box, use_container_width=True)
                    
                    with tab3:
                        st.plotly_chart(fig_bar, use_container_width=True)
                    
                    with tab4:
                        # Afficher le tableau des donn√©es
                        df_display = df.copy()
                        df_display['√âcart_pourcentage'] = df_display['√âcart_pourcentage'].round(2)
                        df_display = df_display.sort_values('√âcart_pourcentage', ascending=False)
                        
                        if 'P√©rim√®tre' in df_display.columns:
                            df_display.columns = ['Fichier', '√âcart (%)', 'P√©rim√®tre']
                            df_display = df_display[['P√©rim√®tre', 'Fichier', '√âcart (%)']]
                        else:
                            df_display.columns = ['Fichier', '√âcart (%)']
                        
                        st.dataframe(df_display, use_container_width=True)
        
        # Section Comparaison d√©taill√©e
        st.markdown("---")
        st.markdown("## üîç Comparaison d√©taill√©e")
        
        if available_files:
            col1, col2 = st.columns([3, 1])
            
            with col1:
                # Cr√©er des options avec informations de p√©rim√®tre pour l'affichage
                if selected_scope == "TOUS":
                    file_options = []
                    for file_name in available_files:
                        scope = files_data[file_name].get('scope', 'Unknown')
                        display_name = f"[{scope}] {file_name.split(':')[-1] if ':' in file_name else file_name}"
                        file_options.append(display_name)
                    
                    selected_display = st.selectbox(
                        "S√©lectionnez un fichier √† comparer:",
                        file_options,
                        help="Seuls les fichiers ayant une version am√©lior√©e sont affich√©s"
                    )
                    
                    # Retrouver le nom de fichier original
                    selected_index = file_options.index(selected_display)
                    selected_file = available_files[selected_index]
                else:
                    selected_file = st.selectbox(
                        "S√©lectionnez un fichier √† comparer:",
                        available_files,
                        help="Seuls les fichiers ayant une version am√©lior√©e sont affich√©s"
                    )
            
            with col2:
                disable_filter = st.checkbox(
                    "D√©sactiver le filtrage",
                    value=False,
                    help="D√©sactive le filtrage automatique pour voir le texte brut avec les m√©tadonn√©es LLM"
                )
            
            if selected_file:
                data = files_data[selected_file]
                original_text = data['original']
                improved_text_raw = data['improved']
                
                # Appliquer le filtrage par d√©faut
                improved_text = filter_transcription_segments(original_text, improved_text_raw)
                reduction = len(improved_text_raw) - len(improved_text)
                
                if not disable_filter:
                    st.info(f"üîß Filtrage activ√© par d√©faut - R√©duction: {reduction:,} caract√®res ({reduction/len(improved_text_raw)*100:.1f}%)")
                else:
                    # D√©sactiver le filtrage si demand√©
                    improved_text = improved_text_raw
                    st.info("‚ö†Ô∏è Filtrage d√©sactiv√© - Affichage du texte brut avec m√©tadonn√©es LLM")
                
                # Afficher les informations du fichier
                st.markdown("---")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("Longueur originale", f"{len(original_text):,} caract√®res")
                
                with col2:
                    st.metric("Longueur am√©lior√©e", f"{len(improved_text):,} caract√®res")
                
                with col3:
                    diff = len(improved_text) - len(original_text)
                    st.metric("Diff√©rence", f"{diff:+,} caract√®res")
                
                # Effectuer la comparaison
                if st.button("üîç Comparer les textes", type="primary"):
                    with st.spinner("Analyse en cours..."):
                        original_html, improved_html, start1, start2 = align_and_compare_texts(
                            original_text, improved_text, min_common_words
                        )
                        
                        # Calculer les statistiques
                        stats = calculate_diff_stats(original_text[start1:], improved_text[start2:])
                        
                        # Afficher les statistiques
                        st.markdown("### üìä Statistiques de comparaison")
                        
                        col1, col2, col3, col4, col5 = st.columns(5)
                        
                        with col1:
                            st.metric("Tokens identiques", stats['equal'])
                        
                        with col2:
                            st.metric("Tokens modifi√©s", stats['replaced'])
                        
                        with col3:
                            st.metric("Tokens supprim√©s", stats['deleted'])
                        
                        with col4:
                            st.metric("Tokens ajout√©s", stats['inserted'])
                        
                        with col5:
                            st.metric("% de changement", f"{stats['change_percentage']:.1f}%")
                        
                        if start1 > 0 or start2 > 0:
                            st.info(f"Alignement automatique d√©tect√©. D√©but de comparaison : position {start1} (original) / {start2} (am√©lior√©)")
                        
                        # Afficher la comparaison c√¥te √† c√¥te avec scroll synchronis√©
                        st.markdown("### üîÑ Comparaison d√©taill√©e")
                        
                        # Composant HTML complet avec JavaScript int√©gr√©
                        sync_compare_html = f"""
                        <div style="display: flex; gap: 20px; margin: 20px 0;">
                            <div style="flex: 1;">
                                <h4 style="color: #ffffff; margin-bottom: 10px;">üìÑ Transcription originale</h4>
                                <div id="original-transcript" style="border: 2px solid #444; padding: 15px; border-radius: 8px; height: 400px; overflow-y: auto; background-color: #1e1e1e; color: #ffffff; font-family: monospace; line-height: 1.6;">
                                    {original_html}
                                </div>
                            </div>
                            <div style="flex: 1;">
                                <h4 style="color: #ffffff; margin-bottom: 10px;">‚ú® Transcription am√©lior√©e</h4>
                                <div id="improved-transcript" style="border: 2px solid #444; padding: 15px; border-radius: 8px; height: 400px; overflow-y: auto; background-color: #1e1e1e; color: #ffffff; font-family: monospace; line-height: 1.6;">
                                    {improved_html}
                                </div>
                            </div>
                        </div>
                        
                        <script>
                        (function() {{
                            let syncInProgress = false;
                            
                            function setupSyncScroll() {{
                                const original = document.getElementById('original-transcript');
                                const improved = document.getElementById('improved-transcript');
                                
                                if (original && improved) {{
                                    original.addEventListener('scroll', function() {{
                                        if (!syncInProgress) {{
                                            syncInProgress = true;
                                            improved.scrollTop = this.scrollTop;
                                            setTimeout(() => {{ syncInProgress = false; }}, 10);
                                        }}
                                    }});
                                    
                                    improved.addEventListener('scroll', function() {{
                                        if (!syncInProgress) {{
                                            syncInProgress = true;
                                            original.scrollTop = this.scrollTop;
                                            setTimeout(() => {{ syncInProgress = false; }}, 10);
                                        }}
                                    }});
                                    
                                    console.log('Scroll synchronization enabled');
                                }} else {{
                                    console.log('Elements not found, retrying...');
                                    setTimeout(setupSyncScroll, 200);
                                }}
                            }}
                            
                            // D√©marrer apr√®s chargement complet
                            if (document.readyState === 'loading') {{
                                document.addEventListener('DOMContentLoaded', setupSyncScroll);
                            }} else {{
                                setupSyncScroll();
                            }}
                        }})();
                        </script>
                        """
                        
                        st.markdown(sync_compare_html, unsafe_allow_html=True)
                        
                        # L√©gende
                        st.markdown("### üé® L√©gende des couleurs")
                        
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            st.markdown('<span style="color: #cccccc; padding: 2px 5px; border: 1px solid #666; border-radius: 3px;">Identique</span>', unsafe_allow_html=True)
                        
                        with col2:
                            st.markdown('<span style="background-color: #8B0000; color: #ffffff; padding: 2px 5px; border-radius: 3px;">Modifi√© (original)</span>', unsafe_allow_html=True)
                        
                        with col3:
                            st.markdown('<span style="background-color: #1E3A8A; color: #ffffff; padding: 2px 5px; border-radius: 3px;">Modifi√© (am√©lior√©)</span>', unsafe_allow_html=True)
                        
                        with col4:
                            st.markdown('<span style="background-color: #166534; color: #ffffff; padding: 2px 5px; border-radius: 3px;">Ajout√©</span>', unsafe_allow_html=True)
        
        else:
            st.warning("Aucun fichier avec version am√©lior√©e trouv√© dans ce dossier.")
    
    else:
        st.warning("Aucun fichier de transcription trouv√© dans ce dossier.")

else:
    st.error(f"Le dossier '{directory}' n'existe pas.")

# Sidebar avec informations
st.sidebar.markdown("## ‚ÑπÔ∏è Information")
st.sidebar.markdown("""
Cette application compare les transcriptions originales avec leurs versions am√©lior√©es par l'IA.

**Fonctionnalit√©s :**
- üéØ **S√©lection par p√©rim√®tre** : BATCH1_MELTING, FINFO, OUTREMER, REGIONS
- üìä **Distribution des √©carts** : Analyse statistique globale et par p√©rim√®tre
- üìà **Visualisations interactives** : Histogrammes, box plots, graphiques
- üîç Alignement automatique des textes
- üé® Surbrillance des diff√©rences
- üìä Statistiques de comparaison
- üîÑ Comparaison c√¥te √† c√¥te

**P√©rim√®tres disponibles :**
- **TOUS** : Vue agr√©g√©e de tous les p√©rim√®tres
- **BATCH1_MELTING** : Transcriptions du lot MELTING
- **FINFO** : Transcriptions FINFO
- **OUTREMER** : Transcriptions Outre-mer
- **REGIONS** : Transcriptions des r√©gions

**Analyses disponibles :**
- üî¢ **Statistiques globales de tokens** : Nombre total de tokens supprim√©s, modifi√©s, ajout√©s
- üìä **Visualisations d√©taill√©es** : Graphiques en secteurs, barres empil√©es, distributions par p√©rim√®tre
- üìà **M√©triques par p√©rim√®tre** : Comparaison d√©taill√©e entre BATCH1_MELTING, FINFO, OUTREMER, REGIONS
- üìã **Tableaux de synth√®se** : Statistiques compl√®tes par fichier et p√©rim√®tre
- üéØ **Pourcentages d'√©carts** : Distribution, moyenne, m√©diane, maximum
- üß† **KPI Analyses NLP** : Types de changements moyens par p√©rim√®tre (orthographique, grammatical, ponctuation, lexical, structurel, ajouts, suppressions)
""")